{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOXdyN9mprdRakdU8zenN1K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parksh-db/database/blob/master/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "tijDa4058vCE",
        "outputId": "8f207a62-5249-4023-e64c-a33d83da7283"
      },
      "source": [
        "#x에 대한 기울기 계산\n",
        "import torch\n",
        "x= torch.tensor(data=[2.0,3.0], requires_grad=True) #requires_grd: 텐서에 대한 기울기\n",
        "y= x ** 2\n",
        "z = 2*y +3 #그래프 결과값 저장\n",
        "#z=2x^2 + 3\n",
        "target = torch.tensor([3.0,4.0]) #목표값\n",
        "loss = torch.sum(torch.abs(z-target)) #z와 목표값 차이의 절대값 계산\n",
        "loss.backward() #연산그래프를 따라가 잎노드 x에 대한 기울기 계산\n",
        "#잎노드: 다른 변수를 통해 계산되는게 아니라 그 자체가 값인 것\n",
        "print(x.grad, y.grad, z.grad)\n",
        "\n",
        "\"\"\"\n",
        "x는 잎노드이기 때문에 기울기가 계산이 된다. 하지만 y와 z는 잎노드가 아니기 때문에 계산이 되지 않고\n",
        "None을 출력한다.\n",
        "\"\"\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 8., 12.]) None None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nx는 잎노드이기 때문에 기울기가 계산이 된다. 하지만 y와 z는 잎노드가 아니기 때문에 계산이 되지 않고\\nNone을 출력한다.\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OStxJp0cqsLq",
        "outputId": "4e698058-669c-47aa-a29a-c6f37267f8e4"
      },
      "source": [
        "\"\"\"\n",
        "- 선형회귀분석: 주어진 데이터를 가장 잘 설명하는 직선 하나를 찾는 것\n",
        "  1. 단순선형회귀: y = w * x + b라는 직선방정식이 있을 때, 데이터를 가장 잘 표현하는 변수 w(가중치)와 b(편차)를 찾는다\n",
        "  2. 다중선형회귀: 독립변수가 여러개\n",
        "- 평균제곱오차: 어떤 (w,b)쌍에 대해 데이터와 얼마나 잘 맞는지 수치적으로 계산하는 척도\n",
        "\"\"\"\n",
        "import torch\n",
        "import torch.nn as nn #linear함수 in torch.nn\n",
        "import torch.optim as optim #경사하강법 알고리즘\n",
        "import torch.nn.init as init #텐서 초기값\n",
        "\n",
        "num_data = 1000 #데이터 수\n",
        "num_epoch = 500 #반복 횟수\n",
        "\n",
        "x= init.uniform_(torch.Tensor(num_data,1), -10,10) # -10부터 10까지 균등하게(Random) 초기화\n",
        "noise = init.normal_(torch.FloatTensor(num_data,1),std=1) #Gaussian Noise(표준편차 1)\n",
        "y = 2*x+3 #y는 x에 대한 종속변수, 아마 y는 잎노드가 아닐 것 이다.\n",
        "#y범위: -17~23\n",
        "y_noise = y + noise #데이터에는 노이즈가 추가된 상태로 들어오는 경우가 많기때문에 noise 생성\n",
        "\n",
        "model = nn.Linear(1,1) #선형회귀모델 생성(x와y 모두 한개의 특성을 가진 데이터 1000개)\n",
        "loss_func = nn.L1Loss() #L1Loss: 모델결과와 y_noise의 차이를 구하는 척도\n",
        "#L1Loss정의: 차이의 절댓값의 평균\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(),lr=0.01) #SGD Optimizer 로드\n",
        "#옵티마이저: 최적화함수, 경사하강법을 적용하여 오차를 줄이고 최적의 가중치와 편차를 근사할 수 있게 하는 역할\n",
        "#SGD: 한번에 들어오는 데이터의 수대로 경사하강법 알고리즘을 적용하는 최적화 함수\n",
        "#lr: 학습률\n",
        "\n",
        "\"\"\"학습부분\"\"\"\n",
        "label = y_noise\n",
        "for i in range(num_epoch): #epoch만큼 반복(epoch: 학습에 한번 사용하는 주기)\n",
        "  optimizer.zero_grad() #기울기 0 초기화(새로운 가중치와 편차에 대해 새로운 기울기 계산)\n",
        "  output = model(x) #모델결과\n",
        "\n",
        "  loss = loss_func(output, label) #output과 noise 차이\n",
        "  loss.backward() \n",
        "  optimizer.step() #기울기에 학습률을 곱하여 업데이트\n",
        "\n",
        "  if i % 10 == 0:\n",
        "    print(loss.data)\n",
        "\n",
        "  param_list = list(model.parameters())\n",
        "  print(param_list[0].item(), param_list[1].item())\n",
        "\n",
        "  \"\"\"\n",
        "  2와 3이라는 가중치와 편차에 가까운 값이 출력\n",
        "  \"\"\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(10.6168)\n",
            "-0.02003997005522251 -0.594229519367218\n",
            "0.028424451127648354 -0.5928295254707336\n",
            "0.07680004835128784 -0.591389536857605\n",
            "0.1251036822795868 -0.589909553527832\n",
            "0.17322435975074768 -0.5883495807647705\n",
            "0.2212374061346054 -0.5867495536804199\n",
            "0.2690793573856354 -0.5850695371627808\n",
            "0.31684747338294983 -0.5833495259284973\n",
            "0.3644672930240631 -0.5815695524215698\n",
            "0.4120020866394043 -0.5797495245933533\n",
            "tensor(8.3077)\n",
            "0.45936548709869385 -0.5778695344924927\n",
            "0.5064345598220825 -0.5758695602416992\n",
            "0.5534356236457825 -0.5738495588302612\n",
            "0.6003048419952393 -0.5717695355415344\n",
            "0.6469343900680542 -0.569609522819519\n",
            "0.6934958696365356 -0.5674295425415039\n",
            "0.7394210696220398 -0.5650495290756226\n",
            "0.7850484848022461 -0.5625695586204529\n",
            "0.8304708003997803 -0.5600095391273499\n",
            "0.8754555583000183 -0.557329535484314\n",
            "tensor(6.1608)\n",
            "0.9200016856193542 -0.5545095205307007\n",
            "0.9642689228057861 -0.5515895485877991\n",
            "1.0080543756484985 -0.5485295653343201\n",
            "1.0510377883911133 -0.5452295541763306\n",
            "1.0938771963119507 -0.5418895483016968\n",
            "1.1360164880752563 -0.5383895635604858\n",
            "1.1775250434875488 -0.5347495675086975\n",
            "1.2183352708816528 -0.530949592590332\n",
            "1.258254885673523 -0.5269495844841003\n",
            "1.2968738079071045 -0.5226495862007141\n",
            "tensor(4.3846)\n",
            "1.3341495990753174 -0.5181095600128174\n",
            "1.36996591091156 -0.5132895708084106\n",
            "1.4037704467773438 -0.5081295967102051\n",
            "1.436189889907837 -0.5027496218681335\n",
            "1.4658007621765137 -0.496969610452652\n",
            "1.4925141334533691 -0.4907495975494385\n",
            "1.5167176723480225 -0.48414960503578186\n",
            "1.5392793416976929 -0.47730961441993713\n",
            "1.5597158670425415 -0.4701696038246155\n",
            "1.5783703327178955 -0.46276959776878357\n",
            "tensor(3.5413)\n",
            "1.5950123071670532 -0.4551095962524414\n",
            "1.610145092010498 -0.4472495913505554\n",
            "1.624050498008728 -0.4392295777797699\n",
            "1.6358541250228882 -0.4309495687484741\n",
            "1.6463984251022339 -0.4225095808506012\n",
            "1.6555863618850708 -0.41390958428382874\n",
            "1.6633570194244385 -0.4051295816898346\n",
            "1.670569658279419 -0.396289587020874\n",
            "1.6765466928482056 -0.38730958104133606\n",
            "1.682050108909607 -0.37826958298683167\n",
            "tensor(3.3544)\n",
            "1.6870124340057373 -0.36916959285736084\n",
            "1.6919747591018677 -0.36006960272789\n",
            "1.6963770389556885 -0.35090959072113037\n",
            "1.7005847692489624 -0.3417295813560486\n",
            "1.7046241760253906 -0.33252957463264465\n",
            "1.7086635828018188 -0.3233295679092407\n",
            "1.712702989578247 -0.3141295611858368\n",
            "1.7165647745132446 -0.3049095571041107\n",
            "1.720068335533142 -0.29564955830574036\n",
            "1.7230584621429443 -0.28632956743240356\n",
            "tensor(3.2530)\n",
            "1.7260485887527466 -0.2770095765590668\n",
            "1.7288520336151123 -0.26766958832740784\n",
            "1.7312768697738647 -0.2582895755767822\n",
            "1.7337017059326172 -0.2489095777273178\n",
            "1.7361265420913696 -0.2395295798778534\n",
            "1.738551378250122 -0.23014958202838898\n",
            "1.7409762144088745 -0.22076958417892456\n",
            "1.743401050567627 -0.21138958632946014\n",
            "1.7458258867263794 -0.20200958847999573\n",
            "1.7482507228851318 -0.1926295906305313\n",
            "tensor(3.1589)\n",
            "1.7506755590438843 -0.1832495927810669\n",
            "1.7531003952026367 -0.17386959493160248\n",
            "1.7555252313613892 -0.16448959708213806\n",
            "1.7579500675201416 -0.15510959923267365\n",
            "1.760374903678894 -0.14572960138320923\n",
            "1.7627997398376465 -0.1363496035337448\n",
            "1.765224575996399 -0.1269696056842804\n",
            "1.7676494121551514 -0.11758960783481598\n",
            "1.7699061632156372 -0.10818960517644882\n",
            "1.7719773054122925 -0.09876960515975952\n",
            "tensor(3.0652)\n",
            "1.7740484476089478 -0.08934960514307022\n",
            "1.776119589805603 -0.07992960512638092\n",
            "1.7778557538986206 -0.07046960294246674\n",
            "1.7795919179916382 -0.06100960075855255\n",
            "1.7813280820846558 -0.05154959857463837\n",
            "1.7830642461776733 -0.04208959639072418\n",
            "1.784800410270691 -0.03262959420681\n",
            "1.7865365743637085 -0.023169592022895813\n",
            "1.788272738456726 -0.013709590770304203\n",
            "1.7900089025497437 -0.004249589517712593\n",
            "tensor(2.9726)\n",
            "1.7917450666427612 0.005210411734879017\n",
            "1.7934812307357788 0.014670412987470627\n",
            "1.7952173948287964 0.02413041517138481\n",
            "1.796953558921814 0.033590417355298996\n",
            "1.7984998226165771 0.04307042062282562\n",
            "1.8000460863113403 0.05255042389035225\n",
            "1.8015923500061035 0.062030427157878876\n",
            "1.8029673099517822 0.07153043150901794\n",
            "1.804342269897461 0.08103043586015701\n",
            "1.8057172298431396 0.09053044021129608\n",
            "tensor(2.8803)\n",
            "1.8070921897888184 0.10003044456243515\n",
            "1.808467149734497 0.10953044891357422\n",
            "1.8098421096801758 0.11903045326471329\n",
            "1.8112170696258545 0.12853045761585236\n",
            "1.8125920295715332 0.13803045451641083\n",
            "1.813777208328247 0.14755044877529144\n",
            "1.814962387084961 0.15707044303417206\n",
            "1.8161475658416748 0.16659043729305267\n",
            "1.8173327445983887 0.1761104315519333\n",
            "1.8185179233551025 0.1856304258108139\n",
            "tensor(2.7882)\n",
            "1.8197450637817383 0.19513042271137238\n",
            "1.820972204208374 0.20463041961193085\n",
            "1.8221993446350098 0.21413041651248932\n",
            "1.8234264850616455 0.2236304134130478\n",
            "1.8246536254882812 0.23313041031360626\n",
            "1.825880765914917 0.24263040721416473\n",
            "1.8271079063415527 0.2521304190158844\n",
            "1.8283350467681885 0.26163041591644287\n",
            "1.8296091556549072 0.2711104154586792\n",
            "1.830883264541626 0.2805904150009155\n",
            "tensor(2.6965)\n",
            "1.8321573734283447 0.29007041454315186\n",
            "1.8334314823150635 0.2995504140853882\n",
            "1.8347055912017822 0.3090304136276245\n",
            "1.835979700088501 0.31851041316986084\n",
            "1.8372538089752197 0.32799041271209717\n",
            "1.8385279178619385 0.3374704122543335\n",
            "1.8398020267486572 0.3469504117965698\n",
            "1.841076135635376 0.35643041133880615\n",
            "1.8423502445220947 0.3659104108810425\n",
            "1.8436243534088135 0.3753904104232788\n",
            "tensor(2.6050)\n",
            "1.8448984622955322 0.38487040996551514\n",
            "1.846172571182251 0.39435040950775146\n",
            "1.8474466800689697 0.4038304090499878\n",
            "1.8487207889556885 0.4133104085922241\n",
            "1.8499948978424072 0.42279040813446045\n",
            "1.851300835609436 0.43225041031837463\n",
            "1.8526067733764648 0.4417104125022888\n",
            "1.8537567853927612 0.45119041204452515\n",
            "1.85506272315979 0.46065041422843933\n",
            "1.8562127351760864 0.47013041377067566\n",
            "tensor(2.5137)\n",
            "1.8575186729431152 0.47959041595458984\n",
            "1.8586686849594116 0.48907041549682617\n",
            "1.859818696975708 0.4985504150390625\n",
            "1.8611246347427368 0.5080103874206543\n",
            "1.8622746467590332 0.5174903869628906\n",
            "1.863580584526062 0.5269503593444824\n",
            "1.8647305965423584 0.5364303588867188\n",
            "1.8658806085586548 0.5459103584289551\n",
            "1.8671865463256836 0.5553703308105469\n",
            "1.86833655834198 0.5648503303527832\n",
            "tensor(2.4225)\n",
            "1.8696424961090088 0.574310302734375\n",
            "1.8707925081253052 0.5837903022766113\n",
            "1.872098445892334 0.5932502746582031\n",
            "1.8732484579086304 0.6027302742004395\n",
            "1.8743984699249268 0.6122102737426758\n",
            "1.8755115270614624 0.6216902732849121\n",
            "1.876624584197998 0.6311702728271484\n",
            "1.8777376413345337 0.6406502723693848\n",
            "1.8788506984710693 0.6501302719116211\n",
            "1.879963755607605 0.6596102714538574\n",
            "tensor(2.3314)\n",
            "1.8810768127441406 0.6690902709960938\n",
            "1.8821898698806763 0.6785702705383301\n",
            "1.883302927017212 0.6880502700805664\n",
            "1.8844159841537476 0.6975302696228027\n",
            "1.8855290412902832 0.7070102691650391\n",
            "1.8865277767181396 0.7164702415466309\n",
            "1.887526512145996 0.7259302139282227\n",
            "1.88857102394104 0.7353702187538147\n",
            "1.889615535736084 0.7448102235794067\n",
            "1.8908042907714844 0.7542302012443542\n",
            "tensor(2.2407)\n",
            "1.8919930458068848 0.7636501789093018\n",
            "1.8931818008422852 0.7730701565742493\n",
            "1.8943705558776855 0.7824901342391968\n",
            "1.895559310913086 0.7919101119041443\n",
            "1.8967480659484863 0.8013300895690918\n",
            "1.8979368209838867 0.8107500672340393\n",
            "1.8991817235946655 0.8201500773429871\n",
            "1.9004266262054443 0.8295500874519348\n",
            "1.901477575302124 0.8389700651168823\n",
            "1.9025285243988037 0.8483900427818298\n",
            "tensor(2.1506)\n",
            "1.9035794734954834 0.8578100204467773\n",
            "1.904630422592163 0.8672299981117249\n",
            "1.9056813716888428 0.8766499757766724\n",
            "1.9067323207855225 0.8860699534416199\n",
            "1.9077832698822021 0.8954899311065674\n",
            "1.9088342189788818 0.9049099087715149\n",
            "1.9098851680755615 0.9143298864364624\n",
            "1.9109361171722412 0.9237498641014099\n",
            "1.911987066268921 0.9331698417663574\n",
            "1.9130380153656006 0.9425898194313049\n",
            "tensor(2.0608)\n",
            "1.9140889644622803 0.9520097970962524\n",
            "1.91513991355896 0.9614297747612\n",
            "1.9160901308059692 0.9708297848701477\n",
            "1.9170403480529785 0.9802297949790955\n",
            "1.9179905652999878 0.9896298050880432\n",
            "1.918940782546997 0.999029815196991\n",
            "1.9198909997940063 1.008429765701294\n",
            "1.9208412170410156 1.0178297758102417\n",
            "1.921791434288025 1.0272297859191895\n",
            "1.9227219820022583 1.0366097688674927\n",
            "tensor(1.9715)\n",
            "1.9236525297164917 1.045989751815796\n",
            "1.924583077430725 1.0553697347640991\n",
            "1.9255136251449585 1.0647497177124023\n",
            "1.9265753030776978 1.074109673500061\n",
            "1.927636981010437 1.0834696292877197\n",
            "1.9286986589431763 1.0928295850753784\n",
            "1.9297603368759155 1.102189540863037\n",
            "1.9308220148086548 1.1115494966506958\n",
            "1.931883692741394 1.1209094524383545\n",
            "1.9329453706741333 1.1302694082260132\n",
            "tensor(1.8827)\n",
            "1.9340070486068726 1.1396293640136719\n",
            "1.9350687265396118 1.1489893198013306\n",
            "1.936002254486084 1.1583293676376343\n",
            "1.9367574453353882 1.1676493883132935\n",
            "1.9374035596847534 1.176949381828308\n",
            "1.9379527568817139 1.1862293481826782\n",
            "1.9384783506393433 1.1954894065856934\n",
            "1.9390039443969727 1.2047494649887085\n",
            "1.9397234916687012 1.213989496231079\n",
            "1.940280795097351 1.2231894731521606\n",
            "tensor(1.7958)\n",
            "1.940838098526001 1.2323894500732422\n",
            "1.9414877891540527 1.2415494918823242\n",
            "1.9421123266220093 1.2506895065307617\n",
            "1.9427368640899658 1.2598295211791992\n",
            "1.9434840679168701 1.2689495086669922\n",
            "1.9442692995071411 1.2780494689941406\n",
            "1.9451498985290527 1.287129521369934\n",
            "1.9460304975509644 1.2962095737457275\n",
            "1.9468932151794434 1.3052695989608765\n",
            "1.9475677013397217 1.3142695426940918\n",
            "tensor(1.7124)\n",
            "1.9482421875 1.3232694864273071\n",
            "1.9490879774093628 1.3322495222091675\n",
            "1.9499337673187256 1.3412295579910278\n",
            "1.9507795572280884 1.3502095937728882\n",
            "1.95192551612854 1.3591495752334595\n",
            "1.9530011415481567 1.3680895566940308\n",
            "1.9539111852645874 1.3770095109939575\n",
            "1.9545191526412964 1.3858895301818848\n",
            "1.9552711248397827 1.394709587097168\n",
            "1.956023097038269 1.4035296440124512\n",
            "tensor(1.6321)\n",
            "1.956802487373352 1.4123296737670898\n",
            "1.957581877708435 1.4211297035217285\n",
            "1.9583112001419067 1.4298896789550781\n",
            "1.9589076042175293 1.4386296272277832\n",
            "1.9595040082931519 1.4473695755004883\n",
            "1.9601004123687744 1.4561095237731934\n",
            "1.9608358144760132 1.4647895097732544\n",
            "1.961571216583252 1.4734694957733154\n",
            "1.962142825126648 1.482129454612732\n",
            "1.9626474380493164 1.4907695055007935\n",
            "tensor(1.5556)\n",
            "1.9632283449172974 1.4993895292282104\n",
            "1.9639257192611694 1.507989525794983\n",
            "1.9646230936050415 1.5165895223617554\n",
            "1.9653204679489136 1.5251895189285278\n",
            "1.9660178422927856 1.5337895154953003\n",
            "1.9667152166366577 1.5423895120620728\n",
            "1.9674125909805298 1.5509895086288452\n",
            "1.9680871963500977 1.5595494508743286\n",
            "1.968818187713623 1.568089485168457\n",
            "1.9695491790771484 1.5766295194625854\n",
            "tensor(1.4814)\n",
            "1.9702577590942383 1.5851495265960693\n",
            "1.9709663391113281 1.5936695337295532\n",
            "1.971674919128418 1.602189540863037\n",
            "1.9724024534225464 1.610649585723877\n",
            "1.9729944467544556 1.6190695762634277\n",
            "1.9737417697906494 1.6274296045303345\n",
            "1.9743143320083618 1.6357696056365967\n",
            "1.9748642444610596 1.6440695524215698\n",
            "1.9752424955368042 1.6522696018218994\n",
            "1.9756468534469604 1.66042959690094\n",
            "tensor(1.4110)\n",
            "1.9759281873703003 1.668569564819336\n",
            "1.9761738777160645 1.6766695976257324\n",
            "1.9764870405197144 1.6847496032714844\n",
            "1.9769304990768433 1.6928095817565918\n",
            "1.977285385131836 1.7008495330810547\n",
            "1.9776685237884521 1.708849549293518\n",
            "1.9782414436340332 1.716829538345337\n",
            "1.978875756263733 1.7247495651245117\n",
            "1.9795100688934326 1.7326695919036865\n",
            "1.9796417951583862 1.7405096292495728\n",
            "tensor(1.3468)\n",
            "1.9797735214233398 1.748349666595459\n",
            "1.9798856973648071 1.7561696767807007\n",
            "1.979964017868042 1.7639096975326538\n",
            "1.9801173210144043 1.7716296911239624\n",
            "1.9800584316253662 1.7793097496032715\n",
            "1.9801387786865234 1.786929726600647\n",
            "1.9803509712219238 1.794529676437378\n",
            "1.9805631637573242 1.8021296262741089\n",
            "1.980798602104187 1.8096896409988403\n",
            "1.9808850288391113 1.8172296285629272\n",
            "tensor(1.2880)\n",
            "1.9807347059249878 1.8247296810150146\n",
            "1.9805843830108643 1.832229733467102\n",
            "1.9804776906967163 1.8396897315979004\n",
            "1.9803709983825684 1.8471497297286987\n",
            "1.9801981449127197 1.854549765586853\n",
            "1.9803211688995361 1.8619097471237183\n",
            "1.9804441928863525 1.8692697286605835\n",
            "1.9803794622421265 1.8765897750854492\n",
            "1.9804414510726929 1.8838697671890259\n",
            "1.980597734451294 1.891129732131958\n",
            "tensor(1.2334)\n",
            "1.9809224605560303 1.8983497619628906\n",
            "1.9812471866607666 1.9055697917938232\n",
            "1.981458067893982 1.9127697944641113\n",
            "1.9817149639129639 1.9199497699737549\n",
            "1.9819320440292358 1.927089810371399\n",
            "1.9819368124008179 1.9341697692871094\n",
            "1.9819415807724 1.9412497282028198\n",
            "1.9821549654006958 1.9482897520065308\n",
            "1.9822216033935547 1.9553097486495972\n",
            "1.9822094440460205 1.962309718132019\n",
            "tensor(1.1828)\n",
            "1.9823004007339478 1.9692697525024414\n",
            "1.9824330806732178 1.9762097597122192\n",
            "1.9826325178146362 1.983109712600708\n",
            "1.9827980995178223 1.9899897575378418\n",
            "1.9825644493103027 1.996809720993042\n",
            "1.9827117919921875 2.003549814224243\n",
            "1.9827443361282349 2.0102698802948\n",
            "1.9827709197998047 2.0169498920440674\n",
            "1.9827367067337036 2.0236098766326904\n",
            "1.9827231168746948 2.030249834060669\n",
            "tensor(1.1368)\n",
            "1.982828974723816 2.036869764328003\n",
            "1.9831150770187378 2.0434696674346924\n",
            "1.9832898378372192 2.0500497817993164\n",
            "1.9833816289901733 2.0565297603607178\n",
            "1.9832072257995605 2.0629496574401855\n",
            "1.9834731817245483 2.0692696571350098\n",
            "1.9838093519210815 2.0755696296691895\n",
            "1.9841455221176147 2.081869602203369\n",
            "1.98459792137146 2.0881495475769043\n",
            "1.9850611686706543 2.094409465789795\n",
            "tensor(1.0956)\n",
            "1.9853707551956177 2.100649356842041\n",
            "1.985632061958313 2.1068294048309326\n",
            "1.985994815826416 2.1129894256591797\n",
            "1.9864851236343384 2.1191294193267822\n",
            "1.9867885112762451 2.1252293586730957\n",
            "1.9872108697891235 2.13128924369812\n",
            "1.9873580932617188 2.1373093128204346\n",
            "1.9876353740692139 2.1432292461395264\n",
            "1.988153338432312 2.1490893363952637\n",
            "1.9886713027954102 2.154949426651001\n",
            "tensor(1.0589)\n",
            "1.9892797470092773 2.1607494354248047\n",
            "1.9897809028625488 2.166529417037964\n",
            "1.9902820587158203 2.172309398651123\n",
            "1.9908367395401 2.1780693531036377\n",
            "1.9909361600875854 2.183769464492798\n",
            "1.991079568862915 2.1894094944000244\n",
            "1.9914982318878174 2.195009469985962\n",
            "1.991856336593628 2.200589418411255\n",
            "1.992308259010315 2.206129312515259\n",
            "1.992760181427002 2.2116692066192627\n",
            "tensor(1.0267)\n",
            "1.993212103843689 2.2172091007232666\n",
            "1.9934269189834595 2.222689151763916\n",
            "1.9937812089920044 2.228149175643921\n",
            "1.9943022727966309 2.2335691452026367\n",
            "1.9947504997253418 2.238929033279419\n",
            "1.9948517084121704 2.2442290782928467\n",
            "1.9947559833526611 2.24950909614563\n",
            "1.9947268962860107 2.254749059677124\n",
            "1.9946892261505127 2.259948968887329\n",
            "1.9947900772094727 2.2651288509368896\n",
            "tensor(0.9981)\n",
            "1.99494206905365 2.2702689170837402\n",
            "1.9950940608978271 2.275408983230591\n",
            "1.9953662157058716 2.280529022216797\n",
            "1.9955620765686035 2.2856290340423584\n",
            "1.9956756830215454 2.2907090187072754\n",
            "1.9958628416061401 2.295768976211548\n",
            "1.9960500001907349 2.3008289337158203\n",
            "1.996376872062683 2.3058290481567383\n",
            "1.9967948198318481 2.3108091354370117\n",
            "1.997219443321228 2.3157691955566406\n",
            "tensor(0.9724)\n",
            "1.997644066810608 2.3207292556762695\n",
            "1.9980686902999878 2.3256893157958984\n",
            "1.9985582828521729 2.330629348754883\n",
            "1.9988176822662354 2.3355093002319336\n",
            "1.9990124702453613 2.34036922454834\n",
            "1.9990296363830566 2.3452091217041016\n",
            "1.9989091157913208 2.350029230117798\n",
            "1.9984815120697021 2.3547892570495605\n",
            "1.9980539083480835 2.3595492839813232\n",
            "1.9977481365203857 2.3642892837524414\n",
            "tensor(0.9488)\n",
            "1.9979699850082397 2.3689491748809814\n",
            "1.9981918334960938 2.3736090660095215\n",
            "1.9984853267669678 2.3782291412353516\n",
            "1.9987807273864746 2.382829189300537\n",
            "1.9989858865737915 2.387409210205078\n",
            "1.9991910457611084 2.3919692039489746\n",
            "1.9993962049484253 2.396529197692871\n",
            "1.999567985534668 2.401069164276123\n",
            "1.9997397661209106 2.405609130859375\n",
            "1.9998035430908203 2.4100890159606934\n",
            "tensor(0.9279)\n",
            "1.9997327327728271 2.4145090579986572\n",
            "1.9994663000106812 2.4189090728759766\n",
            "1.9993982315063477 2.4232890605926514\n",
            "1.9992977380752563 2.427628993988037\n",
            "1.999197244644165 2.431968927383423\n",
            "1.9991185665130615 2.436288833618164\n",
            "1.999039888381958 2.4406087398529053\n",
            "1.9989612102508545 2.4449286460876465\n",
            "1.998882532119751 2.4492485523223877\n",
            "1.998985767364502 2.4535486698150635\n",
            "tensor(0.9090)\n",
            "1.999089002609253 2.4578487873077393\n",
            "1.999192237854004 2.462148904800415\n",
            "1.999485731124878 2.4663689136505127\n",
            "1.9996976852416992 2.470568895339966\n",
            "1.9999909400939941 2.47472882270813\n",
            "2.0001585483551025 2.478848934173584\n",
            "2.0004360675811768 2.4829490184783936\n",
            "2.000481367111206 2.486968994140625\n",
            "2.000370502471924 2.490968942642212\n",
            "2.0001909732818604 2.4949488639831543\n",
            "tensor(0.8919)\n",
            "2.000127077102661 2.498908758163452\n",
            "2.0002598762512207 2.5028488636016846\n",
            "2.0006277561187744 2.506748914718628\n",
            "2.000995635986328 2.5106489658355713\n",
            "2.001363515853882 2.5145490169525146\n",
            "2.0018012523651123 2.5184290409088135\n",
            "2.0022389888763428 2.5223090648651123\n",
            "2.0027365684509277 2.5261690616607666\n",
            "2.0032341480255127 2.530029058456421\n",
            "2.0037317276000977 2.533889055252075\n",
            "tensor(0.8766)\n",
            "2.003974676132202 2.537688970565796\n",
            "2.004305601119995 2.5414490699768066\n",
            "2.0045135021209717 2.545189142227173\n",
            "2.0047214031219482 2.548929214477539\n",
            "2.0048635005950928 2.5525691509246826\n",
            "2.0049636363983154 2.5561492443084717\n",
            "2.0052106380462646 2.559709310531616\n",
            "2.0053322315216064 2.563249349594116\n",
            "2.0054538249969482 2.566789388656616\n",
            "2.005730152130127 2.5702693462371826\n",
            "tensor(0.8634)\n",
            "2.0057742595672607 2.57370924949646\n",
            "2.005749464035034 2.577129364013672\n",
            "2.0059900283813477 2.58048939704895\n",
            "2.006054401397705 2.583829402923584\n",
            "2.0061187744140625 2.5871694087982178\n",
            "2.006396532058716 2.5904693603515625\n",
            "2.006674289703369 2.5937693119049072\n",
            "2.006833791732788 2.597029209136963\n",
            "2.006993293762207 2.6002891063690186\n",
            "2.007152795791626 2.603549003601074\n",
            "tensor(0.8523)\n",
            "2.0071768760681152 2.60676908493042\n",
            "2.0073282718658447 2.6099090576171875\n",
            "2.007479667663574 2.613049030303955\n",
            "2.007549524307251 2.616168975830078\n",
            "2.007502794265747 2.6192688941955566\n",
            "2.007456064224243 2.622368812561035\n",
            "2.0072367191314697 2.625448703765869\n",
            "2.0068840980529785 2.6285088062286377\n",
            "2.006814479827881 2.6315088272094727\n",
            "2.006744861602783 2.6345088481903076\n",
            "tensor(0.8428)\n",
            "2.0068771839141846 2.6374287605285645\n",
            "2.006910562515259 2.6403286457061768\n",
            "2.006943941116333 2.643228530883789\n",
            "2.0069773197174072 2.6461284160614014\n",
            "2.0070106983184814 2.6490283012390137\n",
            "2.0070440769195557 2.651928186416626\n",
            "2.0075082778930664 2.654768228530884\n",
            "2.0078237056732178 2.657588243484497\n",
            "2.0078670978546143 2.6603682041168213\n",
            "2.0079104900360107 2.6631481647491455\n",
            "tensor(0.8345)\n",
            "2.0079538822174072 2.6659281253814697\n",
            "2.0078272819519043 2.6686880588531494\n",
            "2.008075475692749 2.6713881492614746\n",
            "2.0083236694335938 2.6740882396698\n",
            "2.0085718631744385 2.676788330078125\n",
            "2.00885009765625 2.6794283390045166\n",
            "2.0091283321380615 2.682068347930908\n",
            "2.008892059326172 2.684648275375366\n",
            "2.0086557865142822 2.687228202819824\n",
            "2.0087456703186035 2.6897683143615723\n",
            "tensor(0.8275)\n",
            "2.0086517333984375 2.692288398742676\n",
            "2.008869171142578 2.6947684288024902\n",
            "2.0088582038879395 2.6972084045410156\n",
            "2.0087201595306396 2.699608325958252\n",
            "2.008761405944824 2.7019882202148438\n",
            "2.008802652359009 2.7043681144714355\n",
            "2.0088438987731934 2.7067480087280273\n",
            "2.008885145187378 2.709127902984619\n",
            "2.0090084075927734 2.711467981338501\n",
            "2.009037733078003 2.7137680053710938\n",
            "tensor(0.8217)\n",
            "2.009249448776245 2.716048002243042\n",
            "2.0093934535980225 2.7183079719543457\n",
            "2.0096280574798584 2.720547914505005\n",
            "2.0098626613616943 2.722787857055664\n",
            "2.0100972652435303 2.7250277996063232\n",
            "2.010331869125366 2.7272677421569824\n",
            "2.010411500930786 2.729487657546997\n",
            "2.010491132736206 2.7317075729370117\n",
            "2.0107192993164062 2.733907461166382\n",
            "2.0109474658966064 2.736107349395752\n",
            "tensor(0.8167)\n",
            "2.011211633682251 2.738267421722412\n",
            "2.0111403465270996 2.740387439727783\n",
            "2.0112338066101074 2.7424874305725098\n",
            "2.0113272666931152 2.7445874214172363\n",
            "2.011420726776123 2.746687412261963\n",
            "2.011514186859131 2.7487874031066895\n",
            "2.0116076469421387 2.750887393951416\n",
            "2.01165771484375 2.752927303314209\n",
            "2.0115466117858887 2.754927396774292\n",
            "2.0114355087280273 2.756927490234375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqEbFT1wquXL"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as oprtim\n",
        "import torch.nn.init as init\n",
        "\n",
        "num_data = 1000\n",
        "num_epoch = 10000\n",
        "\n",
        "noise = init.normal_(torch.FloatTensor(num_data,1),std = 1)\n",
        "x = init.uniform_(torch.Tensor(num_data,1), -15,15)\n",
        "y = (x ** 2) + 3\n",
        "y_noise = y + noise\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(1,6),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(6,10),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(10,6),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(6,1),\n",
        ")\n",
        "\n",
        "loss_func = nn.L1Loss()\n",
        "optimizer = optim.SGD(model.parameters(),lr=0.0002)\n",
        "\n",
        "loss_array = []\n",
        "for i in range(num_epoch):\n",
        "  optimizer.zero_grad()\n",
        "  output = model(x)\n",
        "  loss = loss_func(output,y_noise)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  loss_array.append(loss)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "goy5mz2yAt5i",
        "outputId": "1bebcd73-7331-46f3-87b7-0e9aa3338756"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(loss_array)\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}